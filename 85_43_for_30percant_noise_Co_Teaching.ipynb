{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahjalalkhan16/ml_learning/blob/main/85_43_for_30percant_noise_Co_Teaching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfClU6q3C48f",
        "outputId": "5679fa9d-2071-4626-9c73-742d71535427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.1.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.20.1+cu124)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.17.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->medmnist)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->medmnist)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->medmnist)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->medmnist)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->medmnist)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->medmnist)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->medmnist)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->medmnist)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->medmnist)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->medmnist)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=0c1225aad8353841a300bf0ed0cdd304b74aca3ad3fb9e4c9497832189c70953\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fire, autoray, nvidia-cusparse-cu12, nvidia-cudnn-cu12, diastatic-malt, nvidia-cusolver-cu12, medmnist, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 diastatic-malt-2.15.2 fire-0.7.0 medmnist-3.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RT_NEA1tD6S-"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "import medmnist\n",
        "from medmnist import OrganAMNIST as DATASETS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset, Subset\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zK2o3ItLGKqG"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "Epochs = 20\n",
        "# lr = 0.1\n",
        "noise_rate = 0.5\n",
        "# quality = 0.5\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QT_kQm4GluHO"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import os\n",
        "\n",
        "# def set_seed(seed=0):\n",
        "#     # Basic seeds\n",
        "#     random.seed(seed)\n",
        "#     np.random.seed(seed)\n",
        "#     torch.manual_seed(seed)\n",
        "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "#     # CUDA/cuDNN\n",
        "#     if torch.cuda.is_available():\n",
        "#         torch.cuda.manual_seed(seed)\n",
        "#         torch.cuda.manual_seed_all(seed)\n",
        "#         torch.backends.cudnn.deterministic = True\n",
        "#         torch.backends.cudnn.benchmark = False\n",
        "# # Call this at the start of your script\n",
        "# set_seed(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WVhdh0F6G9yp"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load and preprocess data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean =[0.5], std=[0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHEgVa1GHA3h",
        "outputId": "e28bfc79-ed29-4757-dd92-fcb677a9a6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/organamnist.npz?download=1 to /root/.medmnist/organamnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38.2M/38.2M [00:23<00:00, 1.60MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/organamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/organamnist.npz\n",
            "Train samples: 18287, Validation samples: 3918, Test samples: 3920\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "train_dataset = DATASETS(split='train', transform=transform, download=True)\n",
        "val_dataset = DATASETS(split='val', transform=transform, download=True)\n",
        "test_dataset = DATASETS(split='test', transform=transform, download=True)\n",
        "\n",
        "# Concatenate datasets\n",
        "full_dataset = ConcatDataset([train_dataset, val_dataset, test_dataset])\n",
        "all_labels = np.array([sample[1] for sample in full_dataset]).flatten()\n",
        "\n",
        "# Balance dataset\n",
        "class_counts = Counter(all_labels)\n",
        "min_class_count = min(class_counts.values())\n",
        "balanced_indices = []\n",
        "\n",
        "for cls in class_counts.keys():\n",
        "    cls_indices = np.where(all_labels == cls)[0]\n",
        "    selected_indices = np.random.choice(cls_indices, min_class_count, replace=False)\n",
        "    balanced_indices.extend(selected_indices)\n",
        "\n",
        "balanced_dataset = Subset(full_dataset, balanced_indices)\n",
        "\n",
        "# Define split sizes\n",
        "train_size = int(0.7 * len(balanced_dataset))\n",
        "val_size = int(0.15 * len(balanced_dataset))\n",
        "test_size = len(balanced_dataset) - train_size - val_size\n",
        "\n",
        "# Perform dataset split\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    balanced_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# Define class for introducing noisy labels\n",
        "class NoisyMedMNIST(Dataset):\n",
        "    def __init__(self, dataset, noise_ratio=noise_rate):\n",
        "        self.dataset = dataset\n",
        "        self.noise_ratio = noise_ratio\n",
        "        self.noisy_labels = self.apply_label_noise()\n",
        "\n",
        "    def apply_label_noise(self):\n",
        "        labels = np.array([sample[1] for sample in self.dataset])\n",
        "        n_samples = len(labels)\n",
        "        n_noisy = int(n_samples * self.noise_ratio)\n",
        "        noisy_indices = np.random.choice(n_samples, n_noisy, replace=False)\n",
        "\n",
        "        num_classes = len(np.unique(labels))\n",
        "        for idx in noisy_indices:\n",
        "            original_label = labels[idx]\n",
        "            possible_labels = [l for l in range(num_classes) if l != original_label]\n",
        "            labels[idx] = np.random.choice(possible_labels)\n",
        "        return labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, _ = self.dataset[idx]\n",
        "        label = self.noisy_labels[idx]\n",
        "        return image, label\n",
        "\n",
        "# Apply noisy labels to training dataset\n",
        "noisy_train_dataset = NoisyMedMNIST(train_dataset, noise_ratio=noise_rate)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(noisy_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0kUo5w8zT3v",
        "outputId": "9226a07c-d1a4-4e76-858b-dd4428b436f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Labels: [[9]\n",
            " [3]\n",
            " [0]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [6]\n",
            " [4]\n",
            " [0]]\n",
            "Noisy Labels: [[ 9]\n",
            " [ 0]\n",
            " [ 1]\n",
            " [10]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [10]\n",
            " [ 7]\n",
            " [ 0]]\n"
          ]
        }
      ],
      "source": [
        "# Print original and noisy labels for verification\n",
        "print(\"Original Labels:\", np.array([train_dataset[idx][1] for idx in range(10)]))\n",
        "print(\"Noisy Labels:\", noisy_train_dataset.noisy_labels[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Zl3xQcT9sOFX"
      },
      "outputs": [],
      "source": [
        "n_qubits = 8\n",
        "n_layers = 6\n",
        "dev = qml.device('default.qubit', wires=n_qubits)\n",
        "# dev = qml.device(\"default.mixed\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(inputs, weights):\n",
        "\n",
        "    # Embed classical data into quantum state (with padding if needed)\n",
        "    qml.templates.AmplitudeEmbedding(inputs, wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "    # qml.templates.AngleEmbedding(inputs, wires=range(n_qubits), rotation='X')\n",
        "\n",
        "    # Initial Encoder\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(weights[0, i, 0], wires=i)\n",
        "        qml.RY(weights[0, i, 1], wires=i)\n",
        "        # qml.PauliX(wires=i)\n",
        "        qml.RZ(weights[1, i, 0], wires=i)\n",
        "\n",
        "    for i in range(n_layers):\n",
        "        qml.CNOT(wires=[i % n_qubits, (i + 1) % n_qubits])\n",
        "        # qml.RZ(weights[2, i, 0], wires=i % n_qubits)\n",
        "        # qml.RX(weights[2, i, 1], wires=i % n_qubits)\n",
        "\n",
        "    # Entangling layers\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, (i + 2) % n_qubits])\n",
        "\n",
        "\n",
        "    # Hierarchical Quantum Convolutional Layer (HQCL)\n",
        "    for i in range(n_layers):\n",
        "        #Entangling Quantum Convolutional Layer\n",
        "        for j in range(n_qubits):\n",
        "            qml.RY(weights[i, j, 0], wires=j)\n",
        "            qml.CY(wires=[j, (j + 1) % n_qubits])\n",
        "            qml.RZ(weights[i, j, 1], wires=j)\n",
        "        qml.CNOT(wires = [i % n_qubits, (i + 1) % n_qubits])\n",
        "        qml.Hadamard(wires=i)\n",
        "\n",
        "        #Quantum Convolutional layers\n",
        "        for j in range(n_qubits):\n",
        "            qml.RX(weights[i, j, 0], wires=j)\n",
        "            qml.RY(weights[i, j, 1], wires=j)\n",
        "            qml.CNOT(wires=[j, (j + 1) % n_qubits])  # Circular entanglement\n",
        "\n",
        "    #Custom Entangling with Quantum Convolutional Layer\n",
        "    for j in range(n_qubits):\n",
        "        qml.RX(weights[i, j, 0], wires=j)\n",
        "        qml.CNOT(wires=[j, (j + 1) % n_qubits])\n",
        "        qml.RZ(weights[i, j, 1], wires=j)\n",
        "\n",
        "    # Adaptive Quantum Pooling\n",
        "    phi_values = [weights[2, i, 0] for i in range(n_qubits // 2)]\n",
        "\n",
        "    for i in range(n_qubits // 2):\n",
        "        phi = torch.tensor([0.2*i], requires_grad=True)\n",
        "        qml.CNOT(wires=[i, n_qubits - 1 - i])\n",
        "        qml.RY(phi, wires=n_qubits - 1 - i)\n",
        "        qml.RY(phi_values[i], wires=n_qubits - 1 - i)\n",
        "        qml.CNOT(wires=[i, n_qubits - 1 - i])\n",
        "\n",
        "    # Quantum AttenuFouritation(Attenuation+RZ rotation+Fourier)\n",
        "    for i in range(n_qubits):\n",
        "        qml.Toffoli(wires=[i, (i+1) % n_qubits, (i+2) % n_qubits])  # Multi-controlled attention mechanism\n",
        "        qml.RX(np.pi/2, wires=i)\n",
        "        for j in range(i):\n",
        "            qml.CPhase(np.pi / (2 ** (i - j)), wires=[j, i])  # Controlled phase rotation\n",
        "        qml.Hadamard(wires=i)   # Fourier Transform\n",
        "\n",
        "    # for i in range(n_qubits):\n",
        "    #     # qml.CSWAP(wires=[i, (i+1) % n_qubits, (i+2) % n_qubits])  # Multi-controlled swap\n",
        "    #     qml.SISWAP(wires=[i, (i+1) % n_qubits])  # Multi-controlled swap\n",
        "    #     qml.RY(np.pi/2, wires=i)\n",
        "    #     qml.RX(np.pi/2, wires=i)\n",
        "    #     qml.RZ(np.pi/2, wires=i)\n",
        "\n",
        "    qml.RX(np.pi, wires=0)\n",
        "    qml.RY(np.pi, wires= 1)\n",
        "    qml.RZ(np.pi, wires=2)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "\n",
        "\n",
        "    # Measure PauliZ and PauliX for more varied information\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)] + [qml.expval(qml.PauliX(i)) for i in range(n_qubits)]\n",
        "\n",
        "# Define the weight shapes for the quantum circuit\n",
        "weight_shapes = {\n",
        "    \"weights\": (n_layers, n_qubits, 3)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9LlImTMT9-zS"
      },
      "outputs": [],
      "source": [
        "class SimpleQNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleQNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(128*7*7, 64)\n",
        "        self.quantum_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
        "        self.fc2 = nn.Linear(n_qubits*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.quantum_layer(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kM_0zzSI-gdd"
      },
      "outputs": [],
      "source": [
        "class PureQNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PureQNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 64) #modified to output 64\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.q_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
        "        self.fc = nn.Linear(n_qubits*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.q_layer(x)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qwwXaV4g-pTF"
      },
      "outputs": [],
      "source": [
        "modelA = SimpleQNN(num_classes=11).to(device)\n",
        "modelB = PureQNN(num_classes=11).to(device)\n",
        "modelC = PureQNN(num_classes=11).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.0003)\n",
        "optimizerB = torch.optim.Adam(modelB.parameters(), lr=0.0003)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1r9p6Z_Hbm-m"
      },
      "outputs": [],
      "source": [
        "def rank_pruning(outputs, labels, keep_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Removes the most uncertain samples using confidence scores.\n",
        "    Ensures at least 20% of the batch is kept.\n",
        "    \"\"\"\n",
        "    confidence_scores = torch.max(torch.softmax(outputs, dim=1), dim=1)[0]\n",
        "\n",
        "    # Ensure at least 20% of samples are always used\n",
        "    min_keep = max(int(len(confidence_scores) * 0.2), 1)\n",
        "\n",
        "    threshold = torch.quantile(confidence_scores, max(1 - keep_ratio, 0.2))  # Avoiding NaN by keeping min 20%\n",
        "    mask = confidence_scores >= threshold\n",
        "\n",
        "    if mask.sum() < min_keep:\n",
        "        sorted_conf = torch.sort(confidence_scores, descending=True)[0]\n",
        "        threshold = sorted_conf[min_keep - 1]  # Take the 20% highest confidence\n",
        "        mask = confidence_scores >= threshold\n",
        "\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Iecmal54hbI1"
      },
      "outputs": [],
      "source": [
        "# Forgetting Rate Scheduler (Increasing Noise Filter Over Time)\n",
        "def forget_rate_scheduler(epoch, max_epochs, initial_keep_ratio=0.8, final_keep_ratio=0.5):\n",
        "    \"\"\"Gradually reduces the keep ratio as training progresses.\"\"\"\n",
        "    return max(final_keep_ratio, initial_keep_ratio - (epoch / max_epochs) * (initial_keep_ratio - final_keep_ratio))\n",
        "\n",
        "# Rank Pruning (Confidence-Based Selection)\n",
        "def rank_pruning(outputs, labels, keep_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Removes the most uncertain samples using confidence scores.\n",
        "    Ensures at least 20% of the batch is kept.\n",
        "    \"\"\"\n",
        "    confidence_scores = torch.max(torch.softmax(outputs, dim=1), dim=1)[0]\n",
        "\n",
        "    # Ensure at least 20% of samples are always used\n",
        "    min_keep = max(int(len(confidence_scores) * 0.2), 1)\n",
        "\n",
        "    threshold = torch.quantile(confidence_scores, max(1 - keep_ratio, 0.2))  # Avoid NaN by keeping min 20%\n",
        "    mask = confidence_scores >= threshold\n",
        "\n",
        "    if mask.sum() < min_keep:\n",
        "        sorted_conf = torch.sort(confidence_scores, descending=True)[0]\n",
        "        threshold = sorted_conf[min_keep - 1]  # Take the 20% highest confidence\n",
        "        mask = confidence_scores >= threshold\n",
        "\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fG-Kqyg_hf96"
      },
      "outputs": [],
      "source": [
        "# Custom Symmetric Cross-Entropy Loss\n",
        "class SymmetricCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.1):\n",
        "        super(SymmetricCrossEntropyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce_loss(inputs, targets)\n",
        "        num_classes = inputs.size(1)\n",
        "        targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=num_classes).float().to(inputs.device)\n",
        "        inputs_probs = torch.softmax(inputs, dim=1)\n",
        "        reverse_ce_loss = -(targets_one_hot * torch.log(inputs_probs + 1e-10)).sum(dim=1)\n",
        "        return ((1 - self.alpha) * ce_loss + self.alpha * reverse_ce_loss).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVgpzVOQhI8v",
        "outputId": "6dd728e9-f2e3-45aa-d2d6-88fcc871c9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:16<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - LossA: 2.3347, LossB: 2.3512, AccuracyA: 24.76%, AccuracyB: 18.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:22<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 - LossA: 2.2710, LossB: 2.2983, AccuracyA: 30.93%, AccuracyB: 22.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:27<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 - LossA: 2.2160, LossB: 2.2543, AccuracyA: 33.48%, AccuracyB: 25.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:30<00:00,  1.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 - LossA: 2.1680, LossB: 2.2122, AccuracyA: 34.63%, AccuracyB: 28.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:28<00:00,  1.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 - LossA: 2.1234, LossB: 2.1706, AccuracyA: 36.24%, AccuracyB: 29.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:27<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 - LossA: 2.0783, LossB: 2.1315, AccuracyA: 37.88%, AccuracyB: 30.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:18<00:00,  1.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 - LossA: 2.0320, LossB: 2.0916, AccuracyA: 38.71%, AccuracyB: 30.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:16<00:00,  1.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 - LossA: 1.9848, LossB: 2.0539, AccuracyA: 39.89%, AccuracyB: 30.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:31<00:00,  1.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 - LossA: 1.9373, LossB: 2.0200, AccuracyA: 40.64%, AccuracyB: 30.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:24<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 - LossA: 1.8809, LossB: 1.9822, AccuracyA: 41.46%, AccuracyB: 31.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:21<00:00,  1.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 - LossA: 1.8305, LossB: 1.9456, AccuracyA: 42.39%, AccuracyB: 32.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:18<00:00,  1.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 - LossA: 1.7737, LossB: 1.9162, AccuracyA: 43.26%, AccuracyB: 32.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:19<00:00,  1.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 - LossA: 1.7221, LossB: 1.8729, AccuracyA: 44.12%, AccuracyB: 32.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:21<00:00,  1.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 - LossA: 1.6616, LossB: 1.8295, AccuracyA: 44.88%, AccuracyB: 32.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:28<00:00,  1.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 - LossA: 1.6008, LossB: 1.7843, AccuracyA: 45.62%, AccuracyB: 32.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:37<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 - LossA: 1.5390, LossB: 1.7361, AccuracyA: 46.21%, AccuracyB: 33.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:28<00:00,  1.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 - LossA: 1.4791, LossB: 1.6797, AccuracyA: 47.08%, AccuracyB: 33.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:27<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 - LossA: 1.4149, LossB: 1.6279, AccuracyA: 48.07%, AccuracyB: 33.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:27<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 - LossA: 1.3527, LossB: 1.5742, AccuracyA: 48.78%, AccuracyB: 33.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 286/286 [07:25<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 - LossA: 1.2932, LossB: 1.5143, AccuracyA: 49.38%, AccuracyB: 33.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.0003)\n",
        "optimizerB = torch.optim.Adam(modelB.parameters(), lr=0.0003)\n",
        "criterion = SymmetricCrossEntropyLoss().to(device)\n",
        "\n",
        "all_labelsA, all_labelsB = [], []\n",
        "all_probsA, all_probsB = [], []\n",
        "all_lossesA, all_lossesB = [], []\n",
        "all_predictionsA, all_predictionsB = [], []\n",
        "\n",
        "for epoch in range(Epochs):\n",
        "    modelA.train()\n",
        "    modelB.train()\n",
        "\n",
        "    running_lossA, running_lossB = 0.0, 0.0\n",
        "    correctA, correctB = 0.0, 0.0\n",
        "\n",
        "    forget_rate = forget_rate_scheduler(epoch, Epochs)\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.view(-1).long().to(device)\n",
        "\n",
        "        optimizerA.zero_grad()\n",
        "        optimizerB.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        outputsA = modelA(images)\n",
        "        outputsB = modelB(images)\n",
        "\n",
        "        # Apply dynamic rank pruning\n",
        "        maskA = rank_pruning(outputsA, labels, keep_ratio=forget_rate)\n",
        "        maskB = rank_pruning(outputsB, labels, keep_ratio=forget_rate)\n",
        "\n",
        "        # Apply co-teaching: Each model trains on the other’s selected samples\n",
        "        if maskA.sum() > 0 and maskB.sum() > 0:\n",
        "            lossA_filtered = criterion(outputsA[maskB], labels[maskB])\n",
        "            lossB_filtered = criterion(outputsB[maskA], labels[maskA])\n",
        "        else:\n",
        "            lossA_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "            lossB_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "\n",
        "        # Backpropagation\n",
        "        lossA_filtered.backward()\n",
        "        lossB_filtered.backward()\n",
        "        optimizerA.step()\n",
        "        optimizerB.step()\n",
        "\n",
        "        running_lossA += lossA_filtered.item()\n",
        "        running_lossB += lossB_filtered.item()\n",
        "\n",
        "        # Compute Accuracy\n",
        "        _, predictedA = torch.max(outputsA, 1)\n",
        "        _, predictedB = torch.max(outputsB, 1)\n",
        "\n",
        "        correctA += (predictedA == labels).sum().item()\n",
        "        correctB += (predictedB == labels).sum().item()\n",
        "\n",
        "        all_labelsA.extend(labels.cpu().numpy())\n",
        "        all_labelsB.extend(labels.cpu().numpy())\n",
        "\n",
        "        # We now detach the tensor from the computation graph prior to converting to numpy\n",
        "        all_probsA.extend(outputsA.detach().cpu().numpy()) # detach\n",
        "        all_probsB.extend(outputsB.detach().cpu().numpy()) # detach\n",
        "\n",
        "        all_lossesA.append(lossA_filtered.detach().cpu().numpy().item()) # detach and extract scalar\n",
        "        all_lossesB.append(lossB_filtered.detach().cpu().numpy().item()) # detach and extract scalar\n",
        "\n",
        "\n",
        "        all_predictionsA.extend(predictedA.cpu().numpy())\n",
        "        all_predictionsB.extend(predictedB.cpu().numpy())\n",
        "\n",
        "\n",
        "    # Compute final accuracy\n",
        "    accuracyA = 100 * correctA / len(train_loader.dataset)\n",
        "    accuracyB = 100 * correctB / len(train_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{Epochs} - LossA: {running_lossA/len(train_loader):.4f}, LossB: {running_lossB/len(train_loader):.4f}, AccuracyA: {accuracyA:.2f}%, AccuracyB: {accuracyB:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ok5Brw3sZKoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6424eaee-5ed2-401d-f5e7-eed4d7aada1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 62/62 [00:27<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for noise rate: 0.5 is 62.11734693877551%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "modelA.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images, labels = images.to(device),labels.to(device)\n",
        "        outputs = modelA(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        labels = labels.squeeze()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100*correct/total\n",
        "    print(f\"Accuracy for noise rate: {noise_rate} is {accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DAGE41nyrAqW"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Optimizers\n",
        "# optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.0003)\n",
        "# optimizerB = torch.optim.Adam(modelB.parameters(), lr=0.0003)\n",
        "# criterion = SymmetricCrossEntropyLoss().to(device)\n",
        "\n",
        "# # Tracking Lists\n",
        "# all_labelsA, all_labelsB = [], []\n",
        "# all_probsA, all_probsB = [], []\n",
        "# all_lossesA, all_lossesB = [], []\n",
        "# all_predictionsA, all_predictionsB = [], []\n",
        "\n",
        "# for epoch in range(Epochs):\n",
        "#     modelA.train()\n",
        "#     modelB.train()\n",
        "\n",
        "#     running_lossA, running_lossB = 0.0, 0.0\n",
        "#     correctA, correctB = 0, 0\n",
        "\n",
        "#     forget_rate = forget_rate_scheduler(epoch, Epochs)\n",
        "\n",
        "#     for images, labels in tqdm(train_loader):\n",
        "#         images, labels = images.to(device), labels.view(-1).long().to(device)\n",
        "\n",
        "#         optimizerA.zero_grad()\n",
        "#         optimizerB.zero_grad()\n",
        "\n",
        "#         # Forward Pass\n",
        "#         outputsA = modelA(images)\n",
        "#         outputsB = modelB(images)\n",
        "\n",
        "#         # Apply dynamic rank pruning\n",
        "#         maskA = rank_pruning(outputsA, labels, keep_ratio=forget_rate)\n",
        "#         maskB = rank_pruning(outputsB, labels, keep_ratio=forget_rate)\n",
        "\n",
        "#         # Convert Boolean masks to indices\n",
        "#         idxA = maskA.nonzero(as_tuple=True)[0]\n",
        "#         idxB = maskB.nonzero(as_tuple=True)[0]\n",
        "\n",
        "#         # Apply co-teaching: Each model trains on the other’s selected samples\n",
        "#         if len(idxA) > 0 and len(idxB) > 0:\n",
        "#             lossA_filtered = criterion(outputsA[idxB], labels[idxB])\n",
        "#             lossB_filtered = criterion(outputsB[idxA], labels[idxA])\n",
        "#         else:\n",
        "#             lossA_filtered = torch.tensor(0.0, requires_grad=True, device=device)\n",
        "#             lossB_filtered = torch.tensor(0.0, requires_grad=True, device=device)\n",
        "\n",
        "#         # Backpropagation\n",
        "#         lossA_filtered.backward()\n",
        "#         lossB_filtered.backward()\n",
        "#         optimizerA.step()\n",
        "#         optimizerB.step()\n",
        "\n",
        "#         running_lossA += lossA_filtered.item()\n",
        "#         running_lossB += lossB_filtered.item()\n",
        "\n",
        "#         # Compute Accuracy\n",
        "#         _, predictedA = torch.max(outputsA, 1)\n",
        "#         _, predictedB = torch.max(outputsB, 1)\n",
        "\n",
        "#         correctA += (predictedA == labels).sum().item()\n",
        "#         correctB += (predictedB == labels).sum().item()\n",
        "\n",
        "#         # Store results\n",
        "#         all_labelsA.extend(labels.cpu().numpy())\n",
        "#         all_labelsB.extend(labels.cpu().numpy())\n",
        "\n",
        "#         all_probsA.extend(outputsA.detach().cpu().numpy())  # Detach before converting\n",
        "#         all_probsB.extend(outputsB.detach().cpu().numpy())\n",
        "\n",
        "#         # all_lossesA.append(lossA_filtered.detach().cpu().item())  # Extract loss value\n",
        "#         # all_lossesB.append(lossB_filtered.detach().cpu().item())\n",
        "\n",
        "#         all_predictionsA.extend(predictedA.cpu().numpy())\n",
        "#         all_predictionsB.extend(predictedB.cpu().numpy())\n",
        "\n",
        "#     # Store epoch-wise losses instead of batch-wise losses\n",
        "#     epoch_lossA = running_lossA / len(train_loader)\n",
        "#     epoch_lossB = running_lossB / len(train_loader)\n",
        "\n",
        "#     all_lossesA.append(epoch_lossA)  # Append per epoch\n",
        "#     all_lossesB.append(epoch_lossB)  # Append per epoch\n",
        "#     # Compute final accuracy\n",
        "#     accuracyA = 100 * correctA / len(train_loader.dataset)\n",
        "#     accuracyB = 100 * correctB / len(train_loader.dataset)\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}/{Epochs} - LossA: {running_lossA/len(train_loader):.4f}, \"\n",
        "#           f\"LossB: {running_lossB/len(train_loader):.4f}, \"\n",
        "#           f\"AccuracyA: {accuracyA:.2f}%, AccuracyB: {accuracyB:.2f}%\")\n",
        "\n",
        "# # Plot Loss Curves\n",
        "# plt.plot(range(Epochs), all_lossesA, label='Model A Loss')\n",
        "# plt.plot(range(Epochs), all_lossesB, label='Model B Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "S2P1dMRGnnln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "6a97487f-5850-402a-974c-0b415d26a103"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (5720,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c97ef6beae5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_lossesA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Model A Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_lossesB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Model B Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (5720,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot( range(Epochs), all_lossesA, label='Model A Loss')\n",
        "plt.plot( range(Epochs),all_lossesB, label='Model B Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0_v_npPpBDp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(all_lossesA, label='Model A Loss', linestyle='dashed', marker='o')\n",
        "plt.plot(all_lossesB, label='Model B Loss', linestyle='dashed', marker='s')\n",
        "plt.xlabel(\"Batch Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Trends Over Training\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKVxgwlPpQJS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "epochs = range(1, Epochs+1)\n",
        "plt.plot(epochs, accuracy_listA, label=\"Model A Accuracy\", marker='o')\n",
        "plt.plot(epochs, accuracy_listB, label=\"Model B Accuracy\", marker='s')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Model Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wswdFKQpX52"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, pruned_samplesA, label=\"Model A Retained Samples\", marker='o')\n",
        "plt.plot(epochs, pruned_samplesB, label=\"Model B Retained Samples\", marker='s')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Retained Samples\")\n",
        "plt.title(\"Effect of Rank Pruning Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQgVy_ien3nm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the average loss per epoch for Model A\n",
        "epoch_lossesA = np.array(all_lossesA).reshape(Epochs, -1).mean(axis=1)\n",
        "\n",
        "# Calculate the average loss per epoch for Model B\n",
        "epoch_lossesB = np.array(all_lossesB).reshape(Epochs, -1).mean(axis=1)\n",
        "\n",
        "# Plot the average losses per epoch\n",
        "plt.plot(range(Epochs), epoch_lossesA, label='Model A Loss')\n",
        "plt.plot(range(Epochs), epoch_lossesB, label='Model B Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmh0A7ECR1fK"
      },
      "outputs": [],
      "source": [
        "# # Training Function for Co-Teaching\n",
        "# def co_teaching_train(modelA, modelB, train_loader, epochs=10, noise_level=noise_rate):\n",
        "#     optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.0003)\n",
        "#     optimizerB = torch.optim.Adam(modelB.parameters(), lr=0.0003)\n",
        "#     criterion = SymmetricCrossEntropyLoss().to(device)\n",
        "#     all_labelsA, all_labelsB = [], []\n",
        "#     all_probsA, all_probsB = [], []\n",
        "#     all_lossesA, all_lossesB = [], []\n",
        "#     all_predictionsA, all_predictionsB = [], []\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         modelA.train()\n",
        "#         modelB.train()\n",
        "\n",
        "#         running_lossA, running_lossB = 0.0, 0.0\n",
        "#         correctA, correctB = 0.0, 0.0\n",
        "\n",
        "#         forget_rate = forget_rate_scheduler(epoch, epochs)\n",
        "\n",
        "#         for images, labels in tqdm(train_loader):\n",
        "#             images, labels = images.to(device), labels.view(-1).long().to(device)\n",
        "\n",
        "#             optimizerA.zero_grad()\n",
        "#             optimizerB.zero_grad()\n",
        "\n",
        "#             # Forward Pass\n",
        "#             outputsA = modelA(images)\n",
        "#             outputsB = modelB(images)\n",
        "\n",
        "#             # Apply dynamic rank pruning\n",
        "#             maskA = rank_pruning(outputsA, labels, keep_ratio=forget_rate)\n",
        "#             maskB = rank_pruning(outputsB, labels, keep_ratio=forget_rate)\n",
        "\n",
        "#             # Apply co-teaching: Each model trains on the other’s selected samples\n",
        "#             if maskA.sum() > 0 and maskB.sum() > 0:\n",
        "#                 lossA_filtered = criterion(outputsA[maskB], labels[maskB])\n",
        "#                 lossB_filtered = criterion(outputsB[maskA], labels[maskA])\n",
        "#             else:\n",
        "#                 lossA_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "#                 lossB_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "\n",
        "#             # Backpropagation\n",
        "#             lossA_filtered.backward()\n",
        "#             lossB_filtered.backward()\n",
        "#             optimizerA.step()\n",
        "#             optimizerB.step()\n",
        "\n",
        "#             running_lossA += lossA_filtered.item()\n",
        "#             running_lossB += lossB_filtered.item()\n",
        "\n",
        "#             # Compute Accuracy\n",
        "#             _, predictedA = torch.max(outputsA, 1)\n",
        "#             _, predictedB = torch.max(outputsB, 1)\n",
        "\n",
        "#             correctA += (predictedA == labels).sum().item()\n",
        "#             correctB += (predictedB == labels).sum().item()\n",
        "\n",
        "#             all_labelsA.extend(labels.cpu().numpy())\n",
        "#             all_labelsB.extend(labels.cpu().numpy())\n",
        "\n",
        "#             # all_probsA.extend(torch.softmax(outputsA, dim=1).cpu().numpy())\n",
        "#             # all_probsB.extend(torch.softmax(outputsB, dim=1).cpu().numpy())\n",
        "#            # We now detach the tensor from the computation graph prior to converting to numpy\n",
        "#             all_probsA.extend(outputsA.detach().cpu().numpy()) # detach\n",
        "#             all_probsB.extend(outputsB.detach().cpu().numpy()) # detach\n",
        "\n",
        "#             all_lossesA.append(lossA_filtered.detach().cpu().numpy().item()) # detach and extract scalar\n",
        "#             all_lossesB.append(lossB_filtered.detach().cpu().numpy().item()) # detach and extract scalar\n",
        "\n",
        "\n",
        "#             all_predictionsA.extend(predictedA.cpu().numpy())\n",
        "#             all_predictionsB.extend(predictedB.cpu().numpy())\n",
        "\n",
        "\n",
        "#         # Compute final accuracy\n",
        "#         accuracyA = 100 * correctA / len(train_loader.dataset)\n",
        "#         accuracyB = 100 * correctB / len(train_loader.dataset)\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - LossA: {running_lossA/len(train_loader):.4f}, LossB: {running_lossB/len(train_loader):.4f}, AccuracyA: {accuracyA:.2f}%, AccuracyB: {accuracyB:.2f}%\")\n",
        "\n",
        "# # Train Co-Teaching Model\n",
        "# co_teaching_train(modelA, modelB, train_loader, epochs=Epochs, noise_level=noise_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIyGy3E_grsZ"
      },
      "outputs": [],
      "source": [
        "modelB.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images, labels = images.to(device),labels.to(device)\n",
        "        outputs = modelB(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        labels = labels.squeeze()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100*correct/total\n",
        "    print(f\"Accuracy for noise rate: {noise_rate} is {accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkjJXvySYJ78"
      },
      "outputs": [],
      "source": [
        "# # Initialize epoch-level tracking\n",
        "# epoch_lossesA, epoch_lossesB = [], []\n",
        "# epoch_accuraciesA, epoch_accuraciesB = [], []\n",
        "\n",
        "# # For AUC (collect across all epochs)\n",
        "# all_labels = []\n",
        "# all_probsA, all_probsB = [], []\n",
        "\n",
        "# for epoch in range(Epochs):\n",
        "#     modelA.train()\n",
        "#     modelB.train()\n",
        "\n",
        "#     # Per-epoch accumulators\n",
        "#     epoch_lossA, epoch_lossB = 0.0, 0.0\n",
        "#     correctA, correctB = 0, 0\n",
        "#     forget_rate = forget_rate_scheduler(epoch, Epochs)\n",
        "\n",
        "#     for images, labels in tqdm(train_loader):\n",
        "\n",
        "#         images, labels = images.to(device), labels.view(-1).long().to(device)\n",
        "\n",
        "#         optimizerA.zero_grad()\n",
        "#         optimizerB.zero_grad()\n",
        "\n",
        "#         # Forward Pass\n",
        "#         outputsA = modelA(images)\n",
        "#         outputsB = modelB(images)\n",
        "\n",
        "#         # Apply dynamic rank pruning\n",
        "#         maskA = rank_pruning(outputsA, labels, keep_ratio=forget_rate)\n",
        "#         maskB = rank_pruning(outputsB, labels, keep_ratio=forget_rate)\n",
        "\n",
        "#         # Apply co-teaching: Each model trains on the other’s selected samples\n",
        "#         if maskA.sum() > 0 and maskB.sum() > 0:\n",
        "#             lossA_filtered = criterion(outputsA[maskB], labels[maskB])\n",
        "#             lossB_filtered = criterion(outputsB[maskA], labels[maskA])\n",
        "#         else:\n",
        "#             lossA_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "#             lossB_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "\n",
        "#         # Backpropagation\n",
        "#         lossA_filtered.backward()\n",
        "#         lossB_filtered.backward()\n",
        "#         optimizerA.step()\n",
        "#         optimizerB.step()\n",
        "\n",
        "#         running_lossA += lossA_filtered.item()\n",
        "#         running_lossB += lossB_filtered.item()\n",
        "\n",
        "#         # Compute Accuracy\n",
        "#         _, predictedA = torch.max(outputsA, 1)\n",
        "#         _, predictedB = torch.max(outputsB, 1)\n",
        "\n",
        "#         correctA += (predictedA == labels).sum().item()\n",
        "#         correctB += (predictedB == labels).sum().item()\n",
        "\n",
        "#         all_labelsA.extend(labels.cpu().numpy())\n",
        "#         all_labelsB.extend(labels.cpu().numpy())\n",
        "\n",
        "#         # Store probabilities with softmax\n",
        "#         all_probsA.extend(torch.softmax(outputsA, dim=1).detach().cpu().numpy())\n",
        "#         all_probsB.extend(torch.softmax(outputsB, dim=1).detach().cpu().numpy())\n",
        "#         all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "#     # Calculate epoch metrics\n",
        "#     epoch_lossA = running_lossA / len(train_loader)\n",
        "#     epoch_lossB = running_lossB / len(train_loader)\n",
        "#     epoch_lossesA.append(epoch_lossA)\n",
        "#     epoch_lossesB.append(epoch_lossB)\n",
        "\n",
        "#     accuracyA = 100 * correctA / len(train_loader.dataset)\n",
        "#     accuracyB = 100 * correctB / len(train_loader.dataset)\n",
        "#     epoch_accuraciesA.append(accuracyA)\n",
        "#     epoch_accuraciesB.append(accuracyB)\n",
        "\n",
        "# # Correct Visualization\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(epoch_lossesA, label='Model A Loss')\n",
        "# plt.plot(epoch_lossesB, label='Model B Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(epoch_accuraciesA, label='Model A Accuracy')\n",
        "# plt.plot(epoch_accuraciesB, label='Model B Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy (%)')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # Correct AUC Calculation\n",
        "# all_labels = np.array(all_labels)\n",
        "# all_probsA = np.array(all_probsA)\n",
        "# all_probsB = np.array(all_probsB)\n",
        "\n",
        "# # For multi-class AUC with raw labels\n",
        "# try:\n",
        "#     aucA = roc_auc_score(all_labels, all_probsA, multi_class='ovr')\n",
        "#     aucB = roc_auc_score(all_labels, all_probsB, multi_class='ovr')\n",
        "#     print(f\"AUC - Model A: {aucA:.4f}, Model B: {aucB:.4f}\")\n",
        "# except ValueError as e:\n",
        "#     print(f\"AUC calculation error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6vor6BzJM8J"
      },
      "outputs": [],
      "source": [
        "# optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.0003)\n",
        "# optimizerB = torch.optim.Adam(modelB.parameters(), lr=0.0003)\n",
        "# criterion = SymmetricCrossEntropyLoss().to(device)\n",
        "\n",
        "# all_labelsA, all_labelsB = [], []\n",
        "# all_probsA, all_probsB = [], []\n",
        "# all_lossesA, all_lossesB = [], []\n",
        "# all_predictionsA, all_predictionsB = [], []\n",
        "\n",
        "# for epoch in range(Epochs):\n",
        "#     modelA.train()\n",
        "#     modelB.train()\n",
        "\n",
        "#     running_lossA, running_lossB = 0.0, 0.0\n",
        "#     correctA, correctB = 0.0, 0.0\n",
        "\n",
        "#     forget_rate = forget_rate_scheduler(epoch, Epochs)\n",
        "\n",
        "#     for images, labels in tqdm(train_loader):\n",
        "#         images, labels = images.to(device), labels.view(-1).long().to(device)\n",
        "\n",
        "#         optimizerA.zero_grad()\n",
        "#         optimizerB.zero_grad()\n",
        "\n",
        "#         # Forward Pass\n",
        "#         outputsA = modelA(images)\n",
        "#         outputsB = modelB(images)\n",
        "\n",
        "#         # Apply dynamic rank pruning\n",
        "#         maskA = rank_pruning(outputsA, labels, keep_ratio=forget_rate)\n",
        "#         maskB = rank_pruning(outputsB, labels, keep_ratio=forget_rate)\n",
        "\n",
        "#         # Apply co-teaching: Each model trains on the other’s selected samples\n",
        "#         if maskA.sum() > 0 and maskB.sum() > 0:\n",
        "#             lossA_filtered = criterion(outputsA[maskB], labels[maskB])\n",
        "#             lossB_filtered = criterion(outputsB[maskA], labels[maskA])\n",
        "#         else:\n",
        "#             lossA_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "#             lossB_filtered = torch.tensor(0.0, requires_grad=True).to(device)\n",
        "\n",
        "#         # Backpropagation\n",
        "#         lossA_filtered.backward()\n",
        "#         lossB_filtered.backward()\n",
        "#         optimizerA.step()\n",
        "#         optimizerB.step()\n",
        "\n",
        "#         running_lossA += lossA_filtered.item()\n",
        "#         running_lossB += lossB_filtered.item()\n",
        "\n",
        "#         # Compute Accuracy\n",
        "#         _, predictedA = torch.max(outputsA, 1)\n",
        "#         _, predictedB = torch.max(outputsB, 1)\n",
        "\n",
        "#         correctA += (predictedA == labels).sum().item()\n",
        "#         correctB += (predictedB == labels).sum().item()\n",
        "\n",
        "#         all_labelsA.extend(labels.cpu().numpy())\n",
        "#         all_labelsB.extend(labels.cpu().numpy())\n",
        "\n",
        "#         # all_probsA.extend(torch.softmax(outputsA, dim=1).cpu().numpy())\n",
        "#         # all_probsB.extend(torch.softmax(outputsB, dim=1).cpu().numpy())\n",
        "#         # We now detach the tensor from the computation graph prior to converting to numpy\n",
        "#         all_probsA.extend(outputsA.detach().cpu().numpy()) # detach\n",
        "#         all_probsB.extend(outputsB.detach().cpu().numpy()) # detach\n",
        "\n",
        "#         all_lossesA.append(lossA_filtered.detach().cpu().numpy().item()) # detach and extract scalar\n",
        "#         all_lossesB.append(lossB_filtered.detach().cpu().numpy().item()) # detach and extract scalar\n",
        "\n",
        "\n",
        "#         all_predictionsA.extend(predictedA.cpu().numpy())\n",
        "#         all_predictionsB.extend(predictedB.cpu().numpy())\n",
        "\n",
        "\n",
        "#     # Compute final accuracy\n",
        "#     accuracyA = 100 * correctA / len(train_loader.dataset)\n",
        "#     accuracyB = 100 * correctB / len(train_loader.dataset)\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}/{Epochs} - LossA: {running_lossA/len(train_loader):.4f}, LossB: {running_lossB/len(train_loader):.4f}, AccuracyA: {accuracyA:.2f}%, AccuracyB: {accuracyB:.2f}%\")\n",
        "\n",
        "# #visualise\n",
        "\n",
        "# plt.plot(range(Epochs), all_lossesA, label='Model A Loss')\n",
        "# plt.plot( range(Epochs),all_lossesB, label='Model B Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(range(Epochs), all_predictionsA, label='Model A Predictions')\n",
        "# plt.plot(range(Epochs), all_predictionsB, label='Model B Predictions')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Predictions')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(range(Epochs), all_labelsA, label='Model A Labels')\n",
        "# plt.plot(range(Epochs), all_labelsB, label='Model B Labels')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Labels')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(range(Epochs), all_probsA, label='Model A Probabilities')\n",
        "# plt.plot(range(Epochs), all_probsB, label='Model B Probabilities')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Probabilities')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# all_probsA_np = np.array(all_probsA)\n",
        "\n",
        "# auc = roc_auc_score(all_labelsA, all_probsA_np, multi_class='ovr') # Specify 'ovr' for multi-class\n",
        "# print(f\"AUC for Model A: {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJBNyIwkK73a"
      },
      "outputs": [],
      "source": [
        "modelA.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = modelA(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        labels = labels.squeeze()\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tw1B8OweNb6"
      },
      "outputs": [],
      "source": [
        "modelA = SimpleQNN(num_classes=11).to(device)\n",
        "modelB = PureQNN(num_classes=11).to(device)\n",
        "criterion = SymmetricCrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bRsdSITbsu9"
      },
      "outputs": [],
      "source": [
        "def co_teaching_train_step(modelA, modelB, optimizerA, optimizerB, images, labels, noise_level=0.2):\n",
        "    \"\"\"\n",
        "    Perform one co-teaching training step with two QNN models.\n",
        "    \"\"\"\n",
        "    modelA.train()\n",
        "    modelB.train()\n",
        "\n",
        "    # Forward Pass (Model A)\n",
        "    optimizerA.zero_grad()\n",
        "    outputsA = modelA(images)\n",
        "    maskA = rank_pruning(outputsA, labels, keep_ratio=1 - noise_level)\n",
        "\n",
        "    # Forward Pass (Model B)\n",
        "    optimizerB.zero_grad()\n",
        "    outputsB = modelB(images)\n",
        "    maskB = rank_pruning(outputsB, labels, keep_ratio=1 - noise_level)\n",
        "\n",
        "    # Co-Teaching: Each model trains on the other's clean samples\n",
        "    lossA = nn.CrossEntropyLoss()(outputsA[maskB], labels[maskB])\n",
        "    lossB = nn.CrossEntropyLoss()(outputsB[maskA], labels[maskA])\n",
        "\n",
        "    # Backpropagation\n",
        "    lossA.backward()\n",
        "    optimizerA.step()\n",
        "    lossB.backward()\n",
        "    optimizerB.step()\n",
        "\n",
        "    return lossA.item(), lossB.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zIxZJu9b5ar"
      },
      "outputs": [],
      "source": [
        "def train_co_teaching(modelA, modelB, train_loader, epochs=10, noise_level=0.2):\n",
        "    optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.001)\n",
        "    optimizerB = torch.optim.Adam(modelB.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_lossA, running_lossB = 0.0, 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Perform co-teaching training step\n",
        "            lossA, lossB = co_teaching_train_step(modelA, modelB, optimizerA, optimizerB, images, labels, noise_level)\n",
        "\n",
        "            running_lossA += lossA\n",
        "            running_lossB += lossB\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - LossA: {running_lossA:.4f}, LossB: {running_lossB:.4f}\")\n",
        "\n",
        "    print(\"Training Complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhwLq2N7btkV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJMe40lBPBjm"
      },
      "outputs": [],
      "source": [
        "def co_teaching(train_loader, model1, model2, optimizer, criterion, epoch, num_epochs):\n",
        "    model1.train()\n",
        "    model2.train()\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs1 = model1(inputs)\n",
        "        outputs2 = model2(inputs)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss1 = criterion(outputs1, labels)\n",
        "        loss2 = criterion(outputs2, labels)\n",
        "\n",
        "        # Select small loss samples\n",
        "        _, indices1 = torch.topk(loss1, k=int(0.8 * len(loss1)), largest=False)\n",
        "        _, indices2 = torch.topk(loss2, k=int(0.8 * len(loss2)), largest=False)\n",
        "\n",
        "        # Update models using small loss samples (compute mean loss)\n",
        "        loss1 = criterion(outputs1[indices2], labels[indices2]).mean()  # Scalar\n",
        "        loss2 = criterion(outputs2[indices1], labels[indices1]).mean()  # Scalar\n",
        "\n",
        "        loss1.backward()\n",
        "        loss2.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# Define optimizer and scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# optimizer = optim.Adam([\n",
        "#     {\"params\": model.conv1.parameters(), \"lr\": 0.001},\n",
        "#     {\"params\": model.conv2.parameters(), \"lr\": 0.001},\n",
        "#     {\"params\": model.fc1.parameters(), \"lr\": 0.001},\n",
        "#     {\"params\": model.quantum_layer.parameters(), \"lr\": 0.0001},  # Smaller LR for quantum\n",
        "#     {\"params\": model.fc2.parameters(), \"lr\": 0.001},\n",
        "# ])\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = Epochs\n",
        "for epoch in range(num_epochs):\n",
        "    co_teaching(train_loader, model, model, optimizer, criterion, epoch, num_epochs)\n",
        "    scheduler.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} completed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TStkszxV1Hj"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Flatten the labels (MedMNIST labels are 2D)\n",
        "            labels = labels.squeeze()  # Convert shape [batch_size, 1] → [batch_size]\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "evaluate(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}